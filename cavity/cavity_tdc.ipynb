{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "import matplotlib\n",
    "\n",
    "from user_funn.field import D2Field\n",
    "from user_funn.get_net import ForwardNetwork\n",
    "from user_funn.ds import get_data_loader\n",
    "from user_funn.solver import CloudPointSolver\n",
    "from user_funn.geom import line_linspace\n",
    "import user_funn.plot\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(2)\n",
    "\n",
    "# STEP1 data generate\n",
    "batch_num = 1\n",
    "nx = 21\n",
    "\n",
    "field = D2Field([0,2],[0,2])\n",
    "pde_batch_size = nx * nx\n",
    "pde_input = field.get_field_mesh([nx,nx])\n",
    "pde_output = np.zeros([pde_batch_size,3])\n",
    "\n",
    "points_num_per_line = nx * 2 #每条边上用点数量\n",
    "bc_left_input = line_linspace([0,0],[0,2], points_num_per_line)\n",
    "bc_up_input = line_linspace([0,2],[2,2], points_num_per_line)\n",
    "bc_right_input = line_linspace([2,2],[2,0], points_num_per_line)\n",
    "bc_down_input = line_linspace([2,0],[0,0], points_num_per_line)\n",
    "\n",
    "bc_uv_zero_input = np.vstack([bc_left_input, bc_down_input, bc_right_input])\n",
    "bc_uv_up_input = bc_up_input \n",
    "\n",
    "\n",
    "user_funn.plot.scatter_2d_cloud_point_kind([pde_input, bc_uv_zero_input, \\\n",
    "    bc_uv_up_input])\n",
    "\n",
    "from user_funn.geom import add_t\n",
    "time_linspace = np.arange(0,1,0.1)\n",
    "tc_input = add_t(pde_input,np.array([0]))\n",
    "pde_input = add_t(pde_input,time_linspace)\n",
    "bc_uv_zero_input = add_t(bc_uv_zero_input,time_linspace)\n",
    "bc_uv_up_input = add_t(bc_uv_up_input,time_linspace)\n",
    "\n",
    "tc_batchsize = tc_input.shape[0]\n",
    "tc_output = np.zeros([tc_batchsize,3])\n",
    "\n",
    "pde_batchsize = pde_input.shape[0]\n",
    "pde_output = np.zeros([pde_batchsize,3])\n",
    "\n",
    "bc_uv_zero_batchsize = bc_uv_zero_input.shape[0]\n",
    "bc_uv_up_batchsize = bc_uv_up_input.shape[0]\n",
    "bc_uv_zero_output = np.zeros([bc_uv_zero_batchsize, 2])\n",
    "\n",
    "bc_uv_up_output = np.zeros([bc_uv_up_batchsize, 2])\n",
    "bc_uv_up_output[:,0] = np.sin(np.pi*0.5*bc_uv_up_input[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_funn.pde import diff\n",
    "\n",
    "MU = 0.1\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "def pde_loss(model, data):\n",
    "    x_in,y_real = data\n",
    "    x_in.requires_grad=True\n",
    "\n",
    "    t = x_in[:,[0]]\n",
    "    x = x_in[:,[1]]\n",
    "    y = x_in[:,[2]]\n",
    "    x_use = torch.cat((t,x,y),dim = 1)\n",
    "    U = model(x_use)\n",
    "    p = U[:,[0]]\n",
    "    u = U[:,[1]]\n",
    "    v = U[:,[2]]\n",
    "\n",
    "    dudt = diff(u,t)\n",
    "    dvdt = diff(v,t)\n",
    "    dudx = diff(u,x)\n",
    "    dudy = diff(u,y)\n",
    "    dvdx = diff(v,x)\n",
    "    dvdy = diff(v,y)\n",
    "    dpdx = diff(p,x)\n",
    "    dpdy = diff(p,y)\n",
    "\n",
    "    du2dx2 = diff(dudx,x)\n",
    "    du2dy2 = diff(dudy,y)\n",
    "    dv2dx2 = diff(dvdx,x)\n",
    "    dv2dy2 = diff(dvdy,y)\n",
    "\n",
    "    eq1 = u * dudx + v * dudy + dpdx - MU * (du2dx2 + du2dy2) - dudt\n",
    "    eq2 = u * dvdx + v * dvdy + dpdy - MU * (dv2dx2 + dv2dy2) - dvdt\n",
    "    eq3 = dudx + dvdy\n",
    "    loss_val = loss_fn(eq1, y_real[:,[0]]) + loss_fn(eq2, y_real[:,[1]]) + \\\n",
    "        loss_fn(eq3, y_real[:,[2]])\n",
    "    return loss_val\n",
    "\n",
    "\n",
    "from user_funn.bc import data_loss_factory\n",
    "bc_uv_zero_loss = data_loss_factory(loss_fn, [1,2])\n",
    "bc_uv_up_loss = data_loss_factory(loss_fn, [1,2])\n",
    "tc_loss = data_loss_factory(loss_fn, [0,1,2])\n",
    "\n",
    "num_model = 2\n",
    "overlap_length = 0.1\n",
    "solver_list = []\n",
    "for T_id in range(num_model):\n",
    "    solver_list.append(\n",
    "        CloudPointSolver(model = [2, 50, 50, 50, 1],optimizer = \"adam\")\n",
    "    )\n",
    "\n",
    "#\n",
    "# hyperparameter config\n",
    "T_iter = 2\n",
    "t_length_per_iter = 1\n",
    "\n",
    "t_span_start_list, overlap_start_list, t_span_end_list = [], [], []\n",
    "pde_input_list,pde_output_list = [],[]\n",
    "tc_input_list,tc_output_list = [],[]\n",
    "bc_input_list,bc_output_list = [],[]\n",
    "\n",
    "pde_epoch_size = 128\n",
    "bc_epoch_size = 64\n",
    "tc_epoch_size = 256\n",
    "\n",
    "\n",
    "overlap_length = 0.1\n",
    "for T_id in range(T_iter):\n",
    "    t_span_start = T_id * 0.5\n",
    "    overlap_start = (T_id+1) * 0.5\n",
    "    t_span_end = (T_id+1) * 0.5 + overlap_length \n",
    "    t_span_start_list.append(t_span_start)\n",
    "    overlap_start_list.append(overlap_start)\n",
    "    t_span_end_list.append(t_span_end)\n",
    "    \n",
    "    \n",
    "    pde_field = D2Field([t_span_start,t_span_end])\n",
    "    pde_input = pde_field.get_field_rand(pde_epoch_size)\n",
    "    pde_output = np.zeros([pde_epoch_size,1])\n",
    "    pde_input_list.append(pde_input)\n",
    "    pde_output_list.append(pde_output)\n",
    "\n",
    "    # define bc_input and bc_output \n",
    "    bc_input1 = line_linspace([t_span_start,0],[t_span_end,0],bc_epoch_size//2)\n",
    "    bc_input2 = line_linspace([t_span_start,L],[t_span_end,L],bc_epoch_size//2)\n",
    "    bc_input = np.vstack([bc_input1,bc_input2])\n",
    "    bc_output = np.zeros([bc_epoch_size ,1])\n",
    "    bc_input_list.append(bc_input)\n",
    "    bc_output_list.append(bc_output)\n",
    "\n",
    "    # define tc_input and tc_output\n",
    "    if T_id == 0:\n",
    "        tc_input = line_linspace([0,0],[0,L],tc_epoch_size)\n",
    "    else:\n",
    "        tc_field = D2Field([t_span_start, t_span_start+ overlap_length],[0,L])\n",
    "        tc_input = tc_field.get_field_rand(tc_epoch_size)\n",
    "\n",
    "    tc_input_list.append(tc_input)\n",
    "\n",
    "    cloud_point_data = [\n",
    "        [pde_input, pde_output],\n",
    "        [bc_uv_zero_input, bc_uv_zero_output],\n",
    "        [bc_uv_up_input, bc_uv_up_output],\n",
    "        [tc_input, tc_output]\n",
    "        ]\n",
    "\n",
    "\n",
    "tc_input_init = line_linspace([0,0],[0,L],tc_epoch_size)\n",
    "\n",
    "tc_t = tc_input_init[:,0]\n",
    "tc_x = tc_input_init[:,1]\n",
    "\n",
    "tc_output_init = np.sin(n * np.pi * tc_x / L).reshape(tc_epoch_size,1)\n",
    "\n",
    "# TRAIN:BEGIN\n",
    "epoch_num = 6000\n",
    "cloud_point_list = [None for i in range(2)]\n",
    "for epoch_id in range(epoch_num):\n",
    "    for use_model_id in range(2):\n",
    "        t_span_start = use_model_id\n",
    "        overlap_start = use_model_id+1\n",
    "        t_span_end = (use_model_id+1) + overlap_length \n",
    "\n",
    "        # 通信周期\n",
    "        if epoch_id % 10 == 0:\n",
    "            seg_start = np.array([t_span_start,0]).reshape(1,2)\n",
    "\n",
    "            if use_model_id == 0:\n",
    "                tc_output = tc_output_init\n",
    "            else:\n",
    "                tc_output =\\\n",
    "                    solver_list[use_model_id-1].model_eval(\n",
    "                        tc_input_list[use_model_id] \\\n",
    "                        - seg_start + np.array([1,0]).reshape(1,2))\n",
    "            \n",
    "            cloud_point_list[use_model_id] = [\n",
    "                [pde_input_list[use_model_id] - seg_start,\n",
    "                    pde_output_list[use_model_id]],\n",
    "                [tc_input_list[use_model_id] - seg_start,\n",
    "                    tc_output],\n",
    "                [bc_input_list[use_model_id] - seg_start, \n",
    "                    bc_output_list[use_model_id]]\n",
    "            ]\n",
    "        \n",
    "        # 测试周期\n",
    "        if epoch_id % 100 == 0:\n",
    "            print(f'model{use_model_id}',end ='')\n",
    "            solver_list[use_model_id].test_step(\n",
    "                cloud_point_list = cloud_point_list[use_model_id],\n",
    "                loss_list = [pde_loss, tc_loss, bc_loss],\n",
    "                batchsize = [pde_epoch_size, tc_epoch_size, bc_epoch_size],\n",
    "                loss_weight_list = [1,1,1],\n",
    "                print_flag=True)\n",
    "            \n",
    "\n",
    "        solver_list[use_model_id].train_step(\n",
    "            cloud_point_list = cloud_point_list[use_model_id],\n",
    "            loss_list = [pde_loss, tc_loss, bc_loss],\n",
    "            batchsize = [pde_epoch_size, tc_epoch_size, bc_epoch_size],\n",
    "            loss_weight_list = [1,1,1])\n",
    "    \n",
    "# TRAIN:END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
